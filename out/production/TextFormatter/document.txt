Use a simple nn.Embedding layer for the categories, where each category gets mapped to an embedding vector.
This layer would be randomly initialized and trained with the rest of the model, so the embedding vector for each category learns through training.
To incorporate semantic_category and duration_bin as input embeddings alongside the CodeBERT output for method_token, consider concatenating all these embeddings:
However, CodeBERT is primarily trained on code tokens and natural language text, which means it may not inherently capture any relationships between arbitrary labels like semantic_category.
